{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consent between tweets and IMDB rating on TV shows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective:\n",
    "Objective of our project is to analyze the relationships between the tweets that users post on Twitter and the real TV ratings provided by the people on Internet Movie Database (IMDB). The results can be used as a key to business strategies for recommending a TV show based upon tweets along with the IMDB ratings.\n",
    "\n",
    "The Hypothesis of the Project is that, if we fetch tweets related to a particular show and perform the sentimental analysis on the data, then we will be able to compare the analysis results with the overall rating available for that show on IMDB. From the results we try to check whether there is any consent between the two.\n",
    "\n",
    "### Data Description:  \n",
    "The details of the data are as follows:\n",
    "\n",
    "Twitter Data:-\n",
    "1. The tweets with show nameâ€™s hashtag (For e.g., #DesignatedSurvivor) were collected once per week, over a period of two weeks using Twitter REST API.\n",
    "2. The fields which were utilized from the tweets are User Screen name, the actual text and the tweet ID (To avoid redundancy).\n",
    "\n",
    "IMDB Data:-\n",
    "1. The latest ratings for Designated Survivor and Lethal Weapon shows were extracted from IMDB website by writing a Web Scraper using BeautifulSoup parser.\n",
    "2. The fields which were utilized from IMDB show page are rating and number of users voted for that show.\n",
    "3. The Ratings for shows obtained at 18:00 pm CST on 11/17/2016 are as follows:\n",
    "\n",
    "    a. Designated Survivor- 8.1 rating from 10,308 users\n",
    "\n",
    "    b. Lethal Weapon- 7.8 rating from 7,871 users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Loading the data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rima\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1159 positive, 153 negative and 672 neutral training tweet files for both shows\n",
      "\n",
      "The assigned labels are: [1 1 1 ..., 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Loading the Data\"\"\"\n",
    "\n",
    "import hashlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\"\"\" Root folder name, placed parallel to project. Here all training and testing \n",
    "    tweet files are kept. \"\"\"\n",
    "\n",
    "path = 'Project_Data'\n",
    "\n",
    "\"\"\" fetch_tweet_files function returns a list of tweet file names in the folder \n",
    "    directory that end in .txt\"\"\"\n",
    "\n",
    "def fetch_tweet_files(path):\n",
    "    \n",
    "    files_list = []\n",
    "    \n",
    "    for file in (os.listdir(path)):\n",
    "        if file.endswith(\".txt\"):\n",
    "            files_list.append((os.path.join(path) + os.sep + file).replace(\"\\\\\",\"/\"))\n",
    "    \n",
    "    return files_list\n",
    "\n",
    "\"\"\" fetching the positive, negative and neutral training tweet files from directory path\"\"\"\n",
    "\n",
    "pos_train_files = fetch_tweet_files(path + os.sep + 'train' + os.sep + 'all_shows' + os.sep + 'pos')\n",
    "neg_train_files = fetch_tweet_files(path + os.sep + 'train' + os.sep + 'all_shows' + os.sep + 'neg')\n",
    "neutral_train_files = fetch_tweet_files(path + os.sep + 'train' + os.sep + 'all_shows' + os.sep + 'neu')\n",
    "\n",
    "\"\"\" combining all positive, negative and neutral lists into a single list\"\"\"\n",
    "combined_train_files = pos_train_files + neg_train_files + neutral_train_files\n",
    "\n",
    "\"\"\" printing the Number of positive, negative and neutral tweet files\"\"\"\n",
    "\n",
    "print('We have %d positive, %d negative and %d neutral training tweet files for both shows' %\n",
    "      (len(pos_train_files), len(neg_train_files), len(neutral_train_files) ))\n",
    "\n",
    "\n",
    "\"\"\" training_true_labels function is assigning the labels to the tweet files by passing \n",
    "    all training files names in the parameter . Here label '1' is assigned to positive \n",
    "    tweets, label '-1' is assigned to negative tweets and label '0' is assigned to neutral tweets.\n",
    "    This function will return a numpy array of labels assigned to the training tweets.\"\"\"\n",
    "\n",
    "def training_true_labels(train_files):\n",
    "    \n",
    "    positive = 'pos'\n",
    "    negative = 'neg'\n",
    "    neutral = 'neu'\n",
    "    array_list = []\n",
    "    \n",
    "    for files in train_files:\n",
    "        \n",
    "        if(positive in files):\n",
    "            array_list.append(1)\n",
    "        elif(negative in files):\n",
    "            array_list.append(-1)\n",
    "        elif(neutral in files):\n",
    "            array_list.append(0)\n",
    "    \n",
    "        \n",
    "    return np.array(array_list)\n",
    "    \n",
    "\n",
    "labels = training_true_labels(combined_train_files)\n",
    "\n",
    "\"\"\" printing the training labels\"\"\"\n",
    "\n",
    "print (\"\\nThe assigned labels are: %s\" %labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Data Preprocessing and Printing the data shape </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The feature matrix contains 1984 tweets instances with 1609 features\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" preprocessing_Tweet function takes a tweet text as a parameter and doing preprocessing\n",
    "    on tweet text and it returns the tweet after preprocessing\"\"\"\n",
    "\n",
    "def preprocessing_Tweet(tweet):\n",
    "    \n",
    "    #Collapse URLs starting with www.* or https?://* to THIS_IS_A_URL\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','THIS_IS_A_URL',tweet)\n",
    "    \n",
    "    #Collapse Mentions like @username to THIS_IS_A_MENTION\n",
    "    tweet = re.sub('@[^\\s]+','THIS_IS_A_MENTION',tweet)\n",
    "    \n",
    "    #Replace Hastags words to words without hashtags like #Quantico with Quantico\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
    "    \n",
    "    return tweet\n",
    "\n",
    "\"\"\" tokenize function takes a tweet text as a parameter and tokenizing the tweet contents\n",
    "    into tokens list. This function is considering punctuations. Also to handle the negations\n",
    "    in the tweets, whenever the term 'not' appears in the tweet, the tokenizer will change \n",
    "    the two subsequent tokens to have the prefix 'not_' prior to the token.\n",
    "    This function returns a tokens list.\"\"\"\n",
    "\n",
    "def tokenize(text):\n",
    "    \n",
    "    preprocessed_tweet = preprocessing_Tweet(text)\n",
    "    split_text = preprocessed_tweet.lower().split()\n",
    "    final_text =' '.join(split_text)\n",
    "    tokens_list = re.findall(r\"[\\w]+|[^\\w\\s]\", final_text)\n",
    "    \n",
    "    tokens_length = len(tokens_list)\n",
    "    \n",
    "    for i in range(tokens_length):\n",
    "        if tokens_list[i] == 'not':\n",
    "            if (i+1 < tokens_length):\n",
    "                tokens_list[i+1] = 'not_%s' %tokens_list[i+1]\n",
    "            if (i+2 < tokens_length):   \n",
    "                tokens_list[i+2] = 'not_%s' %tokens_list[i+2]\n",
    "                \n",
    "    return tokens_list\n",
    "\n",
    "\"\"\" perform_vectorize function takes all of the combined tweet files names, tokenizer\n",
    "    function, min_df value, max_df value and other parameters. It is vectorizing the\n",
    "    tweets using CountVectorizer method of sklearn package. The input value is taken as\n",
    "    'filename' so that filename mentioned with the path can be extracted and read for\n",
    "    fetching the text. After vectorizing, the vectorize object is used for getting\n",
    "    features matrix. This function returns feature matrix and vectorizer object.\"\"\"    \n",
    "\n",
    "def perform_vectorize(tweets, tokenizer_fn=tokenize, min_df=2,\n",
    "                 max_df=.7, binary=True, ngram_range=(1,1)):\n",
    "    \n",
    "    \n",
    "    vectorizer = CountVectorizer(input='filename', tokenizer=tokenizer_fn, ngram_range=ngram_range, max_df=max_df, \n",
    "                                 min_df=min_df, stop_words=\"english\",  binary=binary, dtype=int)\n",
    "    \n",
    "    X = vectorizer.fit_transform(tweets)\n",
    "    \n",
    "    return X, vectorizer\n",
    "\n",
    "\"\"\" Calling the perform_vectorize method for getting a feature matrix and vectorizer obejct.\n",
    "    Also printing the number of tweets and features in the feature matrix. \"\"\" \n",
    "    \n",
    "matrix, vec = perform_vectorize(combined_train_files)\n",
    "print ('\\nThe feature matrix contains %d tweets instances with %d features\\n' % (matrix.shape[0], matrix.shape[1]))\n",
    "\n",
    "def repeatable_random(seed):\n",
    "    hash = str(seed)\n",
    "    hash = hash.encode('utf-8')\n",
    "    while True:\n",
    "        hash = hashlib.md5(hash).digest()\n",
    "        for c in hash:\n",
    "            yield (c)\n",
    "\n",
    "def repeatable_shuffle(X, y, combined_train_files):\n",
    "    r = repeatable_random(42)\n",
    "    indices = sorted(range(X.shape[0]), key=lambda x: next(r))\n",
    "    return X[indices], y[indices], np.array(combined_train_files)[indices]\n",
    "\n",
    "X, y, filenames = repeatable_shuffle(matrix, labels, combined_train_files )\n",
    "\n",
    "\n",
    "#top_n = 100\n",
    "#top_features = [features[i] for i in indices[:top_n]]\n",
    "#print top_features\n",
    "#print(vec.get_feature_names()[:100])\n",
    "\n",
    "#indices = np.argsort(vec.idf_)[::-1]\n",
    "features = vec.get_feature_names()\n",
    "#top_n = 100\n",
    "#top_features = [features[i] for i in indices[:top_n]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Performance Measure used:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> accuracy_score </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are calculating the average cross-validation accuracy on training as well as test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data has train-test split, as we have manually labelled the tweets collected from Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Model Selection on train-split </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Firstly, we have selected Logistic Regression model with penalty='l2', C=1.0 and random_state=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Average cross validation accuracy on training data= 0.7389\n",
      "\n",
      "The Average cross validation accuracy on training data= 0.7394\n"
     ]
    }
   ],
   "source": [
    "\"\"\" get_clf function returns the Logistic Regression classifier\"\"\"\n",
    "\n",
    "def get_clf():\n",
    "    \n",
    "    return LogisticRegression(penalty='l2', C=1.0, random_state=0)\n",
    "\n",
    "\"\"\" perform_cross_validation function is calculating the accuracy of the data using N-fold\n",
    "    cross validation function. We have used 10 folds.\n",
    "    This function returns the average accuracy for the dataset. \"\"\"\n",
    "\n",
    "def perform_cross_validation(X, y, n_folds, verbose=False):\n",
    "\n",
    "    crossValidation =KFold(len(y), n_folds=n_folds)\n",
    "   \n",
    "    accuracies = []\n",
    "    \n",
    "    for train_idx, test_idx in crossValidation:\n",
    "        \n",
    "        clf = get_clf()\n",
    "        clf.fit(X[train_idx], y[train_idx])\n",
    "        predicted = clf.predict(X[test_idx])\n",
    "        acc = accuracy_score(y[test_idx], predicted)\n",
    "        accuracies.append(acc)\n",
    "        \n",
    "    avg = np.mean(accuracies)\n",
    "    \n",
    "    return avg\n",
    "\n",
    "\"\"\" printing the Average cross validation accuracy on training data. \"\"\"\n",
    " \n",
    "print('\\nThe Average cross validation accuracy on training data= %.4f' %perform_cross_validation(X, y,n_folds=10, verbose=False))\n",
    "\n",
    "print('\\nThe Average cross validation accuracy on training data= %.4f' %perform_cross_validation(X, y,n_folds=15, verbose=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression model with penalty='l1', C=1.0 and random_state=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Average cross validation accuracy on training data= 0.7298\n",
      "\n",
      "The Average cross validation accuracy on training data= 0.7258\n"
     ]
    }
   ],
   "source": [
    "\"\"\" get_clf function returns the Logistic Regression classifier\"\"\"\n",
    "\n",
    "def get_clf():\n",
    "    \n",
    "    return LogisticRegression(penalty='l1', C=1.0, random_state=0)\n",
    "\n",
    "\"\"\" perform_cross_validation function is calculating the accuracy of the data using N-fold\n",
    "    cross validation function. We have used 10 folds.\n",
    "    This function returns the average accuracy for the dataset. \"\"\"\n",
    "\n",
    "def perform_cross_validation(X, y, n_folds, verbose=False):\n",
    "\n",
    "    crossValidation =KFold(len(y), n_folds=n_folds)\n",
    "   \n",
    "    accuracies = []\n",
    "    \n",
    "    for train_idx, test_idx in crossValidation:\n",
    "        \n",
    "        clf = get_clf()\n",
    "        clf.fit(X[train_idx], y[train_idx])\n",
    "        predicted = clf.predict(X[test_idx])\n",
    "        acc = accuracy_score(y[test_idx], predicted)\n",
    "        accuracies.append(acc)\n",
    "        \n",
    "    avg = np.mean(accuracies)\n",
    "    \n",
    "    return avg\n",
    "\n",
    "\"\"\" printing the Average cross validation accuracy on training data. \"\"\"\n",
    " \n",
    "print('\\nThe Average cross validation accuracy on training data= %.4f' %perform_cross_validation(X, y,n_folds=10, verbose=False))\n",
    "\n",
    "print('\\nThe Average cross validation accuracy on training data= %.4f' %perform_cross_validation(X, y,n_folds=15, verbose=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression model with penalty='l2', C=1.0 and random_state=9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Average cross validation accuracy on training data= 0.7389\n",
      "\n",
      "The Average cross validation accuracy on training data= 0.7394\n"
     ]
    }
   ],
   "source": [
    "\"\"\" get_clf function returns the Logistic Regression classifier\"\"\"\n",
    "\n",
    "def get_clf():\n",
    "    \n",
    "    return LogisticRegression(penalty='l2', C=1.0, random_state=9)\n",
    "\n",
    "\"\"\" perform_cross_validation function is calculating the accuracy of the data using N-fold\n",
    "    cross validation function. We have used 10 folds.\n",
    "    This function returns the average accuracy for the dataset. \"\"\"\n",
    "\n",
    "def perform_cross_validation(X, y, n_folds, verbose=False):\n",
    "\n",
    "    crossValidation =KFold(len(y), n_folds=n_folds)\n",
    "   \n",
    "    accuracies = []\n",
    "    \n",
    "    for train_idx, test_idx in crossValidation:\n",
    "        \n",
    "        clf = get_clf()\n",
    "        clf.fit(X[train_idx], y[train_idx])\n",
    "        predicted = clf.predict(X[test_idx])\n",
    "        acc = accuracy_score(y[test_idx], predicted)\n",
    "        accuracies.append(acc)\n",
    "        \n",
    "    avg = np.mean(accuracies)\n",
    "    \n",
    "    return avg\n",
    "\n",
    "\"\"\" printing the Average cross validation accuracy on training data. \"\"\"\n",
    " \n",
    "print('\\nThe Average cross validation accuracy on training data= %.4f' %perform_cross_validation(X, y,n_folds=10, verbose=False))\n",
    "\n",
    "print('\\nThe Average cross validation accuracy on training data= %.4f' %perform_cross_validation(X, y,n_folds=15, verbose=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second, we have selected Support Vector Machine model. Here all default parameters have been used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Average cross validation accuracy on training data for 10 folds: 0.5842\n",
      "\n",
      "The Average cross validation accuracy on training data for 15 folds: 0.5841\n"
     ]
    }
   ],
   "source": [
    "\"\"\" get_clf function returns the Support Vector Machine classifier\"\"\"\n",
    "from sklearn import svm\n",
    "def get_clf():\n",
    "    \n",
    "    return svm.SVC()\n",
    "\n",
    "\"\"\" perform_cross_validation function is calculating the accuracy of the data using N-fold\n",
    "    cross validation function. We have used 10 folds.\n",
    "    This function returns the average accuracy for the dataset. \"\"\"\n",
    "\n",
    "def perform_cross_validation(X, y, n_folds, verbose=False):\n",
    "\n",
    "    crossValidation =KFold(len(y), n_folds=n_folds)\n",
    "   \n",
    "    accuracies = []\n",
    "    \n",
    "    for train_idx, test_idx in crossValidation:\n",
    "        \n",
    "        clf = get_clf()\n",
    "        clf.fit(X[train_idx], y[train_idx])\n",
    "        predicted = clf.predict(X[test_idx])\n",
    "        acc = accuracy_score(y[test_idx], predicted)\n",
    "        accuracies.append(acc)\n",
    "        \n",
    "    avg = np.mean(accuracies)\n",
    "    \n",
    "    return avg\n",
    "\n",
    "\"\"\" printing the Average cross validation accuracy on training data. \"\"\"\n",
    "\n",
    "print('\\nThe Average cross validation accuracy on training data for 10 folds: %.4f' %perform_cross_validation(X, y, n_folds=10, verbose=False))\n",
    "\n",
    "print('\\nThe Average cross validation accuracy on training data for 15 folds: %.4f' %perform_cross_validation(X, y, n_folds=15, verbose=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM model with C=1.0, kernel='linear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Average cross validation accuracy on training data for 10 folds: 0.7182\n",
      "\n",
      "The Average cross validation accuracy on training data for 15 folds: 0.7152\n"
     ]
    }
   ],
   "source": [
    "\"\"\" get_clf function returns the Support Vector Machine classifier\"\"\"\n",
    "from sklearn import svm\n",
    "def get_clf():\n",
    "    \n",
    "    return svm.SVC(C=1.0, kernel='linear')\n",
    "\n",
    "\"\"\" perform_cross_validation function is calculating the accuracy of the data using N-fold\n",
    "    cross validation function. We have used 10 folds.\n",
    "    This function returns the average accuracy for the dataset. \"\"\"\n",
    "\n",
    "def perform_cross_validation(X, y, n_folds, verbose=False):\n",
    "\n",
    "    crossValidation =KFold(len(y), n_folds=n_folds)\n",
    "   \n",
    "    accuracies = []\n",
    "    \n",
    "    for train_idx, test_idx in crossValidation:\n",
    "        \n",
    "        clf = get_clf()\n",
    "        clf.fit(X[train_idx], y[train_idx])\n",
    "        predicted = clf.predict(X[test_idx])\n",
    "        acc = accuracy_score(y[test_idx], predicted)\n",
    "        accuracies.append(acc)\n",
    "        \n",
    "    avg = np.mean(accuracies)\n",
    "    \n",
    "    return avg\n",
    "\n",
    "\"\"\" printing the Average cross validation accuracy on training data. \"\"\"\n",
    "\n",
    "print('\\nThe Average cross validation accuracy on training data for 10 folds: %.4f' %perform_cross_validation(X, y, n_folds=10, verbose=False))\n",
    "\n",
    "print('\\nThe Average cross validation accuracy on training data for 15 folds: %.4f' %perform_cross_validation(X, y, n_folds=15, verbose=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM model with C=1.0, kernel='poly', random_state=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Average cross validation accuracy on training data for 10 folds: 0.5842\n",
      "\n",
      "The Average cross validation accuracy on training data for 15 folds: 0.5841\n"
     ]
    }
   ],
   "source": [
    "\"\"\" get_clf function returns the Support Vector Machine classifier\"\"\"\n",
    "from sklearn import svm\n",
    "def get_clf():\n",
    "    \n",
    "    return svm.SVC(C=1.0, kernel='poly', random_state=8)\n",
    "\n",
    "\"\"\" perform_cross_validation function is calculating the accuracy of the data using N-fold\n",
    "    cross validation function. We have used 10 folds.\n",
    "    This function returns the average accuracy for the dataset. \"\"\"\n",
    "\n",
    "def perform_cross_validation(X, y, n_folds, verbose=False):\n",
    "\n",
    "    crossValidation =KFold(len(y), n_folds=n_folds)\n",
    "   \n",
    "    accuracies = []\n",
    "    \n",
    "    for train_idx, test_idx in crossValidation:\n",
    "        \n",
    "        clf = get_clf()\n",
    "        clf.fit(X[train_idx], y[train_idx])\n",
    "        predicted = clf.predict(X[test_idx])\n",
    "        acc = accuracy_score(y[test_idx], predicted)\n",
    "        accuracies.append(acc)\n",
    "        \n",
    "    avg = np.mean(accuracies)\n",
    "    \n",
    "    return avg\n",
    "\n",
    "\"\"\" printing the Average cross validation accuracy on training data. \"\"\"\n",
    "\n",
    "print('\\nThe Average cross validation accuracy on training data for 10 folds: %.4f' %perform_cross_validation(X, y, n_folds=10, verbose=False))\n",
    "\n",
    "print('\\nThe Average cross validation accuracy on training data for 15 folds: %.4f' %perform_cross_validation(X, y, n_folds=15, verbose=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM model with C=1.0, kernel='poly', degree=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Average cross validation accuracy on training data for 10 folds: 0.5842\n",
      "\n",
      "The Average cross validation accuracy on training data for 15 folds: 0.5841\n"
     ]
    }
   ],
   "source": [
    "\"\"\" get_clf function returns the Support Vector Machine classifier\"\"\"\n",
    "from sklearn import svm\n",
    "def get_clf():\n",
    "    \n",
    "    return svm.SVC(C=1.0, kernel='poly', degree=2)\n",
    "\n",
    "\"\"\" perform_cross_validation function is calculating the accuracy of the data using N-fold\n",
    "    cross validation function. We have used 10 folds.\n",
    "    This function returns the average accuracy for the dataset. \"\"\"\n",
    "\n",
    "def perform_cross_validation(X, y, n_folds, verbose=False):\n",
    "\n",
    "    crossValidation =KFold(len(y), n_folds=n_folds)\n",
    "   \n",
    "    accuracies = []\n",
    "    \n",
    "    for train_idx, test_idx in crossValidation:\n",
    "        \n",
    "        clf = get_clf()\n",
    "        clf.fit(X[train_idx], y[train_idx])\n",
    "        predicted = clf.predict(X[test_idx])\n",
    "        acc = accuracy_score(y[test_idx], predicted)\n",
    "        accuracies.append(acc)\n",
    "        \n",
    "    avg = np.mean(accuracies)\n",
    "    \n",
    "    return avg\n",
    "\n",
    "\"\"\" printing the Average cross validation accuracy on training data. \"\"\"\n",
    "\n",
    "print('\\nThe Average cross validation accuracy on training data for 10 folds: %.4f' %perform_cross_validation(X, y, n_folds=10, verbose=False))\n",
    "\n",
    "print('\\nThe Average cross validation accuracy on training data for 15 folds: %.4f' %perform_cross_validation(X, y, n_folds=15, verbose=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third, we have selected Multinomial Naive Bayes model. Here all default parameters have been used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Average cross validation accuracy on training data for 10 folds: 0.7197\n",
      "\n",
      "The Average cross validation accuracy on training data for 15 folds: 0.7192\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Multinomial Naive Bayel model prediction\"\"\"\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "def get_clf():\n",
    "    \n",
    "    return MultinomialNB()\n",
    "\n",
    "\n",
    "\"\"\" perform_cross_validation function is calculating the accuracy of the data using N-fold\n",
    "    cross validation function. We have used 10 folds.\n",
    "    This function returns the average accuracy for the dataset. \"\"\"\n",
    "\n",
    "def perform_cross_validation(X, y, n_folds, verbose=False):\n",
    "\n",
    "    crossValidation =KFold(len(y), n_folds=n_folds)\n",
    "   \n",
    "    accuracies = []\n",
    "    \n",
    "    for train_idx, test_idx in crossValidation:\n",
    "        \n",
    "        clf = get_clf()\n",
    "        \n",
    "        predicted = clf.fit(X[train_idx], y[train_idx]).predict(X[test_idx])\n",
    "        #print(predicted)               \n",
    "\n",
    "        acc = accuracy_score(y[test_idx], predicted)\n",
    "        accuracies.append(acc)\n",
    "        \n",
    "    avg = np.mean(accuracies)\n",
    "    \n",
    "    return avg\n",
    "\n",
    "\"\"\" printing the Average cross validation accuracy on training data. \"\"\"\n",
    "\n",
    "print('\\nThe Average cross validation accuracy on training data for 10 folds: %.4f' %perform_cross_validation(X, y, n_folds=10, verbose=False))\n",
    "\n",
    "print('\\nThe Average cross validation accuracy on training data for 15 folds: %.4f' %perform_cross_validation(X, y, n_folds=15, verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes model with fit_prior=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Average cross validation accuracy on training data for 10 folds: 0.6799\n",
      "\n",
      "The Average cross validation accuracy on training data for 15 folds: 0.6764\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Multinomial Naive Bayes model prediction\"\"\"\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "def get_clf():\n",
    "    \n",
    "    return MultinomialNB(fit_prior=False)\n",
    "\n",
    "\n",
    "\"\"\" perform_cross_validation function is calculating the accuracy of the data using N-fold\n",
    "    cross validation function. We have used 10 folds.\n",
    "    This function returns the average accuracy for the dataset. \"\"\"\n",
    "\n",
    "def perform_cross_validation(X, y, n_folds, verbose=False):\n",
    "\n",
    "    crossValidation =KFold(len(y), n_folds=n_folds)\n",
    "   \n",
    "    accuracies = []\n",
    "    \n",
    "    for train_idx, test_idx in crossValidation:\n",
    "        \n",
    "        clf = get_clf()\n",
    "        \n",
    "        predicted = clf.fit(X[train_idx], y[train_idx]).predict(X[test_idx])\n",
    "        #print(predicted)               \n",
    "\n",
    "        acc = accuracy_score(y[test_idx], predicted)\n",
    "        accuracies.append(acc)\n",
    "        \n",
    "    avg = np.mean(accuracies)\n",
    "    \n",
    "    return avg\n",
    "\n",
    "\"\"\" printing the Average cross validation accuracy on training data. \"\"\"\n",
    "\n",
    "print('\\nThe Average cross validation accuracy on training data for 10 folds: %.4f' %perform_cross_validation(X, y, n_folds=10, verbose=False))\n",
    "\n",
    "print('\\nThe Average cross validation accuracy on training data for 15 folds: %.4f' %perform_cross_validation(X, y, n_folds=15, verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Average cross validation accuracy on training data for 10 folds: 0.5030\n",
      "\n",
      "The Average cross validation accuracy on training data for 15 folds: 0.5030\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Gaussians Naive Bayes model prediction\"\"\"\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "\n",
    "clf = GaussianNB()\n",
    "\n",
    "def perform_cross_validation(X, y, k=10):\n",
    "\n",
    "    crossValidation =KFold(len(y))\n",
    "   \n",
    "    accuracies = []\n",
    "    \n",
    "    for train_idx, test_idx in crossValidation:\n",
    "        \n",
    "       \n",
    "        clf.fit(X[train_idx], y[train_idx])\n",
    "        \n",
    "        \n",
    "        predicted = clf.predict(X[test_idx])\n",
    "        acc = accuracy_score(y[test_idx], predicted)\n",
    "        accuracies.append(acc)\n",
    "        \n",
    "    avg = np.mean(accuracies)\n",
    "    \n",
    "    return avg\n",
    "\n",
    "perform_cross_validation(X.toarray(), y)\n",
    "\n",
    "\"\"\" printing the Average cross validation accuracy on training data. \"\"\"\n",
    "\n",
    "print('\\nThe Average cross validation accuracy on training data for 10 folds: %.4f' %perform_cross_validation(X.toarray(), y, k=50))\n",
    "\n",
    "print('\\nThe Average cross validation accuracy on training data for 15 folds: %.4f' %perform_cross_validation(X.toarray(), y, k=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Based upon the different model selections using various parameters. We have received best results from Logistic Regression using penalty='l2', C=1.0 and random_state=0. Hence, we have chosen Logistic Regression Model for repoting the performance on testing data. </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Logistic Regression model </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Performance on Full training data and labelled testing data:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" get_clf function returns the Logistic Regression classifier\"\"\"\n",
    "\n",
    "def get_clf():\n",
    "    \n",
    "    return LogisticRegression(C=1.0, random_state=0)\n",
    "\n",
    "\"\"\" perform_cross_validation function is calculating the accuracy of the data using N-fold\n",
    "    cross validation function. We have used 10 folds.\n",
    "    This function returns the average accuracy for the dataset. \"\"\"\n",
    "\n",
    "def perform_cross_validation(X, y, n_folds=10, verbose=False):\n",
    "\n",
    "    crossValidation =KFold(len(y), n_folds=n_folds)\n",
    "   \n",
    "    accuracies = []\n",
    "    \n",
    "    for train_idx, test_idx in crossValidation:\n",
    "        \n",
    "        clf = get_clf()\n",
    "        clf.fit(X[train_idx], y[train_idx])\n",
    "        predicted = clf.predict(X[test_idx])\n",
    "        acc = accuracy_score(y[test_idx], predicted)\n",
    "        accuracies.append(acc)\n",
    "        \n",
    "    avg = np.mean(accuracies)\n",
    "     clf.predict(X[test_idx])\n",
    "    return avg\n",
    "\n",
    "\"\"\" printing the Average cross validation accuracy on training data. \"\"\"\n",
    " \n",
    "print('\\nThe Average cross validation accuracy on training data= %.4f' %perform_cross_validation(X, y, n_folds=10, verbose=False))\n",
    "\n",
    "clf = get_clf()\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "pos_test_files = fetch_tweet_files(path + os.sep + 'test_labelled' + os.sep + 'pos')\n",
    "neg_test_files = fetch_tweet_files(path + os.sep + 'test_labelled' + os.sep + 'neg')\n",
    "neu_test_files = fetch_tweet_files(path + os.sep + 'test_labelled' + os.sep + 'neu')\n",
    "shows_test_files = pos_test_files + neg_test_files + neu_test_files\n",
    "\n",
    "X_labelled_test = vec.transform(shows_test_files)\n",
    "y_labelled_test = np.array([1] * len(pos_test_files) + [-1] * len(neg_test_files) + [0] * len(neu_test_files))\n",
    "print('\\nX_labelled_test represents %d tweets with %d features' % (X_labelled_test.shape[0], X_labelled_test.shape[1]))\n",
    "print('\\ny_labelled_test has %d positive, %d negative and %d neutral labels' % (len(np.where(y_labelled_test==1)[0]),\n",
    "            len(np.where(y_labelled_test==-1)[0]), len(np.where(y_labelled_test==0)[0])))\n",
    "\n",
    "testingAccuracy=accuracy_score(y_labelled_test, clf.predict(X_labelled_test))\n",
    "\n",
    "print('\\nThe Testing accuracy for the labelled tweets= %.4g' %testingAccuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Predicting the unseen tweets for both shows(Designated Survivor and Lethal Weapon)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Fetching the Designated Survivor test files(i.e. unseen tweet files) from the directory\"\"\"\n",
    "\n",
    "designatedSurvivor_test_files = fetch_tweet_files(path + os.sep + 'test_designatedSurvivor')\n",
    "\n",
    "\n",
    "\"\"\" Now, as we don't want to learn a new vocabulary. We are calling .transform\n",
    "    using vectorizer object instead of .fit_transform, which was used earlier\n",
    "    for training. \"\"\"\n",
    "\n",
    "designatedSurvivor_X_test = vec.transform(designatedSurvivor_test_files)\n",
    "\n",
    "\"\"\" printing the number of testing tweets and features in the feature matrix. \"\"\"\n",
    "print('\\ndesignatedSurvivor_X_test represents %d tweets with %d features' % (designatedSurvivor_X_test.shape[0], designatedSurvivor_X_test.shape[1]))\n",
    "\n",
    "designatedSurvivor_pos_count= 0\n",
    "designatedSurvivor_neg_count = 0\n",
    "designatedSurvivor_neutral_count = 0\n",
    "\n",
    "for i in clf.predict(designatedSurvivor_X_test):\n",
    "\n",
    "    if i == 1:\n",
    "        designatedSurvivor_pos_count+= 1\n",
    "    elif i == -1:\n",
    "        designatedSurvivor_neg_count+= 1\n",
    "    elif i == 0:\n",
    "        designatedSurvivor_neutral_count+= 1\n",
    "\n",
    "print (\"No of Positive Designated Survivor tweets predicted: %d\" %designatedSurvivor_pos_count)\n",
    "print (\"No of Negative Designated Survivor tweets predicted: %d\" %designatedSurvivor_neg_count)\n",
    "print (\"No of Neutral Designated Survivor tweets predicted: %d\" %designatedSurvivor_neutral_count)\n",
    "\n",
    "\"\"\" The above steps are now repeated for Lethal Weapon show. \"\"\"\n",
    "\n",
    "\"\"\" Fetching the Lethal Weapon test files(i.e. unseen tweet files) from the directory\"\"\"\n",
    "\n",
    "lethalWeapon_test_files = fetch_tweet_files(path + os.sep + 'test_lethalWeapon')\n",
    "\n",
    "\n",
    "lethalWeapon_X_test = vec.transform(lethalWeapon_test_files)\n",
    "\n",
    "print('\\nlethalWeapon_X_test represents %d tweets with %d features' % (lethalWeapon_X_test.shape[0], lethalWeapon_X_test.shape[1]))\n",
    "\n",
    "lethalWeapon_pos_count= 0\n",
    "lethalWeapon_neg_count = 0\n",
    "lethalWeapon_neutral_count = 0\n",
    "\n",
    "for i in clf.predict(lethalWeapon_X_test):\n",
    "\n",
    "    if i == 1:\n",
    "        lethalWeapon_pos_count+= 1\n",
    "    elif i == -1:\n",
    "        lethalWeapon_neg_count+= 1\n",
    "    elif i == 0:\n",
    "        lethalWeapon_neutral_count+= 1\n",
    "\n",
    "print (\"No of Positive Lethal Weapon tweets predicted: %d\" %lethalWeapon_pos_count)\n",
    "print (\"No of Negative Lethal Weapon tweets predicted: %d\" %lethalWeapon_neg_count)\n",
    "print (\"No of Neutral Lethal Weapon tweets predicted: %d\" %lethalWeapon_neutral_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Performance of predicting the majority class all the time </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our project, majority class is Positive class, whose label is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_maj = np.array([1] * len(designatedSurvivor_test_files))\n",
    "testingAccuracy_maj=accuracy_score(y_maj, clf.predict(designatedSurvivor_X_test))\n",
    "print ('\\nThe Testing accuracy for predicting the majority class all the time (Designated Survivor)= %.4g' %testingAccuracy_maj)\n",
    "\n",
    "y_maj1 = np.array([1] * len(lethalWeapon_test_files))\n",
    "testingAccuracy_maj1=accuracy_score(y_maj1, clf.predict(lethalWeapon_X_test))\n",
    "print ('\\nThe Testing accuracy for predicting the majority class all the time (Lethal Weapon)= %.4g' %testingAccuracy_maj1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Performance of random prediction </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def repeatable_random(seed):\n",
    "    hash = str(seed)\n",
    "    hash = hash.encode('utf-8')\n",
    "    while True:\n",
    "        hash = hashlib.md5(hash).digest()\n",
    "        for c in hash:\n",
    "            yield (c)\n",
    "\n",
    "def repeatable_shuffle(X1, y1, designatedSurvivor_test_files):\n",
    "    r = repeatable_random(42)\n",
    "    indices = sorted(range(X1.shape[0]), key=lambda x: next(r))\n",
    "    return X1[indices], y1[indices], np.array(designatedSurvivor_test_files)[indices]\n",
    "\n",
    "##X1, y1, filenames = repeatable_shuffle(matrix, labels, designatedSurvivor_test_files )\n",
    "\n",
    "testingAccuracy=accuracy_score(y_labelled_test, clf.predict(X_labelled_test))\n",
    "print ('\\nThe Testing accuracy for random prediction (Designated Survivor)= %.4g' %testingAccuracy)\n",
    "\n",
    "y_rand = np.array([1] * len(designatedSurvivor_test_files))\n",
    "testingAccuracy_rand=accuracy_score(y_ran, clf.predict(designatedSurvivor_X_test))\n",
    "print ('\\nThe Testing accuracy for random prediction (Lethal Weapon)= %.4g' %testingAccuracy_rand)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Final conculsion after comparing the results with IMDB</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" The below code is a Web Scraper written for getting the Designated Survivor and Lethal Weapon ratings\n",
    "    and number of users from IMDB \"\"\"\n",
    "rating=[]\n",
    "urlList=[\"http://www.imdb.com/title/tt5296406/?ref_=nv_sr_1\", \"http://www.imdb.com/title/tt5164196/?ref_=nv_sr_1\"]\n",
    "outf = open('imdbDataSet.txt', 'wt')\n",
    "for url in urlList:\n",
    "    url_got = urlopen(url)\n",
    "    soup = BeautifulSoup(url_got.read(), 'html.parser')\n",
    "    for foo in soup.find_all('div', attrs={'class': 'ratingValue'}):\n",
    "        \n",
    "        bar = foo.find('span', attrs={'itemprop': 'ratingValue'})\n",
    "        \n",
    "        bar1 = foo.find('span', attrs={'itemprop': 'bestRating'})\n",
    "       \n",
    "        rating.append(bar.text)\n",
    "        \n",
    "    for name in soup.find_all('div', attrs={'class': 'title_wrapper'}):\n",
    "        b=name.find('h1', attrs={'itemprop': 'name'})\n",
    "    \n",
    "    \n",
    "    print (\"%s rating from IMDB= %s\" %(b.text.rstrip(),bar.text))\n",
    "    obj='%s %s %s  \\n'%(b.text,bar.text,bar1.text)\n",
    "    outf.write(obj)\n",
    "outf.close()\n",
    "\n",
    "'''calculating score '''\n",
    "\n",
    "score=[]\n",
    "score.append((testingAccuracy*designatedSurvivor_pos_count)/(designatedSurvivor_pos_count+designatedSurvivor_neg_count))\n",
    "score.append((testingAccuracy*lethalWeapon_pos_count)/(lethalWeapon_pos_count+lethalWeapon_neg_count))\n",
    "print (\"Positivity from experiment for Designated Survivor= %s\" %(score[0]))\n",
    "print (\"Positivity from experiment for Lethal Weapon= %s\" %(score[1]))\n",
    "\n",
    "'''Conclusion from experiment'''\n",
    "\n",
    "print (\"\\nIt can be noted that the positivity for Designated Survivor(%s) with IMDB rating %s is more than the positivity for Lethal Weapon(%s)with IMDB rating %s \"%(score[0],rating[0],score[1],rating[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: \n",
    "We have analyzed the two TV shows tweets using Sentiment Analysis, and finds the positive percentage sentiment for a TV show and checking the consent of the same with the ratings available for the show on IMDB. On a higher level, it has been concluded that the positivity percentage in the tweets is more for a show which has got more rating on IMDB and vice-versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the top 20 positive and negative model features along with their weights/scores "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Top 20 Positive features along with their weights </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive = clf.coef_[2]\n",
    "featr = vec.get_feature_names()\n",
    "index_sorted =np.argsort(positive)[::-1].tolist()\n",
    "featres_positive = [(featr[i],positive[i]) for i in index_sorted[:20]]\n",
    "print (featres_positive)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Top 20 Negative features along with their weights </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "negative = clf.coef_[0]\n",
    "index_sorted1 =np.argsort(negative)[::-1].tolist()\n",
    "featres_negative = [(featr[i],negative[i]) for i in index_sorted1[:20]]\n",
    "print (featres_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive = clf.coef_[2]\n",
    "featr = vec.get_feature_names()\n",
    "index_sorted =np.argsort(positive)[::-1].tolist()\n",
    "featres_positive = [(featr[i],positive[i]) for i in index_sorted]\n",
    "featres_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "negative = clf.coef_[0]\n",
    "index_sorted1 =np.argsort(negative)[::-1].tolist()\n",
    "featres_negative = [(featr[i],negative[i]) for i in index_sorted1]\n",
    "featres_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neutral = clf.coef_[1]\n",
    "index_sorted2 =np.argsort(neutral)[::-1].tolist()\n",
    "featres_neutral = [(featr[i],neutral[i]) for i in index_sorted2]\n",
    "featres_neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
